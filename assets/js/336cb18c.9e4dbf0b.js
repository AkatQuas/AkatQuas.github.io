"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[4714],{3905:(e,n,t)=>{t.d(n,{Zo:()=>m,kt:()=>h});var a=t(67294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function s(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?s(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},s=Object.keys(e);for(a=0;a<s.length;a++)t=s[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(a=0;a<s.length;a++)t=s[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var l=a.createContext({}),p=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},m=function(e){var n=p(e.components);return a.createElement(l.Provider,{value:n},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,o=e.mdxType,s=e.originalType,l=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),c=p(t),u=o,h=c["".concat(l,".").concat(u)]||c[u]||d[u]||s;return t?a.createElement(h,r(r({ref:n},m),{},{components:t})):a.createElement(h,r({ref:n},m))}));function h(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var s=t.length,r=new Array(s);r[0]=u;var i={};for(var l in n)hasOwnProperty.call(n,l)&&(i[l]=n[l]);i.originalType=e,i[c]="string"==typeof e?e:o,r[1]=i;for(var p=2;p<s;p++)r[p]=t[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},84315:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>s,metadata:()=>i,toc:()=>p});var a=t(87462),o=(t(67294),t(3905));const s={title:"Storage and Running Stateful Applications",sidebar_position:11},r=void 0,i={unversionedId:"kubernetes/pv-pvc",id:"kubernetes/pv-pvc",title:"Storage and Running Stateful Applications",description:"Volume",source:"@site/docs/kubernetes/pv-pvc.md",sourceDirName:"kubernetes",slug:"/kubernetes/pv-pvc",permalink:"/docs/kubernetes/pv-pvc",draft:!1,tags:[],version:"current",sidebarPosition:11,frontMatter:{title:"Storage and Running Stateful Applications",sidebar_position:11},sidebar:"tutorialSidebar",previous:{title:"ConfigMap and Secret",permalink:"/docs/kubernetes/configmap-secret"},next:{title:"Monitoring and Logging",permalink:"/docs/kubernetes/monitoring-n-logging"}},l={},p=[{value:"Volume",id:"volume",level:2},{value:"ConfigMap",id:"configmap",level:2},{value:"Persistent storage",id:"persistent-storage",level:2},{value:"PersistentVolumes and StorageClasses",id:"persistentvolumes-and-storageclasses",level:2},{value:"StatefulSets",id:"statefulsets",level:2},{value:"Persistent Volumes and StatefulSets",id:"persistent-volumes-and-statefulsets",level:2}],m={toc:p};function c(e){let{components:n,...t}=e;return(0,o.kt)("wrapper",(0,a.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"volume"},"Volume"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"Volume")," in this chapter is actually a part of the Pod API. Within a Pod, you can define a set of Volumes. Each Volume can be one of a large number of different types."),(0,o.kt)("p",null,"When you add a Volume to your Pod, you can choose to mount it to an arbitrary location in each running container. This enables your running container to have access to the storage within the Volume. Different containers can mount these Volumes at different locations or can ignore the Volume entirely."),(0,o.kt)("h2",{id:"configmap"},"ConfigMap"),(0,o.kt)("p",null,"In addition to basic files, there are several types of Kubernetes objects that can themselves be mounted into your Pod as a Volume."),(0,o.kt)("p",null,"A ",(0,o.kt)("inlineCode",{parentName:"p"},"ConfigMap")," represents a collection of configuration files. In Kubernetes, you want to have different configurations for the same container image. When you add a ConfigMap-based Volume to your Pod, the files in the ConfigMap show up in the specified directory in your running container."),(0,o.kt)("p",null,"Kubernetes uses the Secret configuration type for secure data, such as database passwords and certificates. In the context of Volumes, a Secret works identically to a Con figMap. It can be attached to a Pod via a Volume and mounted into a running container for use."),(0,o.kt)("hr",null),(0,o.kt)("p",null,"Instead of binding a Volume directly into a Pod, a ",(0,o.kt)("inlineCode",{parentName:"p"},"PersistentVolume")," is created as a separate object. This object is then claimed to a specific Pod by a ",(0,o.kt)("inlineCode",{parentName:"p"},"PersistentVolumeClaim")," and finally mounted into the Pod via this claim."),(0,o.kt)("h2",{id:"persistent-storage"},"Persistent storage"),(0,o.kt)("p",null,"Real-world applications often carry state and record data that we prefer (even insist) not to lose."),(0,o.kt)("p",null,"A ",(0,o.kt)("strong",{parentName:"p"},"volume")," that exists outside the container allows us to save our important data across containers outages. Further, if we have a volume at the pod level, data can be shared between containers in the same application stack and within the same pod."),(0,o.kt)("p",null,"Additionally, a pod can have multiple volumes from a variety of sources."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Temporary disk")),(0,o.kt)("p",null,"One of the easiest ways to achieve improved persistence amid container crashes and data sharing within a pod is to use the ",(0,o.kt)("inlineCode",{parentName:"p"},"emptydir")," volume. This volume type can be used with either the storage volumes of the node machine itself or an optional RAM disk for higher performance."),(0,o.kt)("p",null,"Again, we improve our persistence beyond a single container, but when a pod is removed, the data will be lost. Also, Machine reboot will also clear any data from RAM-type disks. There may be times when we just need some shared temporary space or have containers that process data and hand it off to another container before they die."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: memory-pd\nspec:\n  containers:\n    - image: nginx:latest\n      ports:\n        - containerPort: 80\n      name: memory-pd\n      volumeMounts:\n        - mountPath: /memory-pd\n          name: memory-volume\n  volumes:\n    - name: memory-volume\n      emptyDir:\n        medium: Memory\n# this folder is quite temporary as\n# everything is stored in the node's (minion's) RAM.\n# When the node gets restarted, all the files will be erased.\n")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Cloud volumes")),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("p",null,"Create some Persistent Disks in GCE in advance.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-gce\nspec:\n  containers:\n    - image: nginx:latest\n      ports:\n        - containerPort: 80\n      name: test-gce\n      volumeMounts:\n        - mountPath: /usr/share/nginx/html\n          name: gce-pd\n  volumes:\n    - name: gce-pd\n      gcePersistentDisk:\n        pdName: mysite-volume-1\n        fsType: ext4\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: http-pd\n  labels:\n    name: http-pd\nspec:\n  replicas: 3\n  selector:\n    name: http-pd\n  template:\n    metadata:\n      name: http-pd\n      labels:\n        name: http-pd\n    spec:\n      containers:\n        - image: nginx:latest\n          ports:\n            - containerPort: 80\n          name: http-pd\n          volumeMounts:\n            - mountPath: /usr/share/nginx/html\n              name: gce-pd\n      volumes:\n        - name: gce-pd\n          gcePersistentDisk:\n            pdName: mysite-volume-1\n            fsType: ext4\n            readOnly: true\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Service\nmetadata:\n  name: http-pd\n  labels:\n    name: http-pd\nspec:\n  type: LoadBalancer\n  ports:\n    - name: http\n      protocol: TCP\n      port: 80\n  selector:\n    name: http-pd\n"))),(0,o.kt)("h2",{id:"persistentvolumes-and-storageclasses"},"PersistentVolumes and StorageClasses"),(0,o.kt)("p",null,"We need some way for the application to specify and request storage without being concerned with how that storage is provided."),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"PersistentVolumes")," are similar to ",(0,o.kt)("inlineCode",{parentName:"p"},"volumes")," we created earlier, but they are provided by the cluster administer and are not dependent on a particular pod. This volume can then be claimed by pods using ",(0,o.kt)("inlineCode",{parentName:"p"},"PersistentVolumeClaims"),"."),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"PersistentVolumeClaims")," allows us to specify the details of the storage needed. We can define the amount of storage as well as the access type such as ",(0,o.kt)("inlineCode",{parentName:"p"},"ReadWriteOnce")," (read and write by one node), ",(0,o.kt)("inlineCode",{parentName:"p"},"ReadOnlyMany")," (read-only by multiple nodes), and ",(0,o.kt)("inlineCode",{parentName:"p"},"ReadWriteMany")," (read and write by many nodes)."),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("p",null,"A small example to use PV and PVC.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: database\n  labels:\n    volume: my-volume\nspec:\n  accessModes:\n    - ReadWriteMany\n  capacity:\n    storage: 1Gi\n  nfs:\n    server: 192.168.0.1\n    path: '/exports'\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'# this request "1Gi" of storage in "ReadWriteOnce" mode\n# with a StorageClass of "solidstate" and label of "aws-storage".\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: demo-claim\n  annotations:\n    volume.beta.kubernetes.io/storage-class: \'solidstate\'\nspec:\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi\n  selector:\n    matchLabels:\n      release: \'aws-storage\'\n      volume: my-volume\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# using PVC in ReplicaSets\napiVersion: extensions/v1\nkind: ReplicaSet\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    sepc:\n      containers:\n        - name: database\n          image: mysql\n          resources:\n            requests:\n              cpu: 1\n              memory: 2Gi\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: some-password\n          livenessProbe:\n            tcpSocket:\n              port: 3306\n          ports:\n            - containerPort: 3306\n          volumeMounts:\n            - name: database\n              mountPath: '/var/lib/mysql'\n      volumes:\n        - name: database\n          persistentVolumeClaim:\n            claimName: demo-claim\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# expose mysql ReplicaSet as a Service\napiVersion: v1\nkind: Service\nmetadata:\n  name: mysql\nspec:\n  ports:\n    - port: 3306\n      protocol: TCP\n  selector:\n    app: mysql\n"))),(0,o.kt)("p",null,"Kubernetes provides two other methods for specifying certain groupings or types of storage volumes:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"selectors: labels can be applied to storage volumes and then claims can reference these labels to further filter the volume they are provided.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"StorageClass: it allows us to specify a storage provisioner and parameters for the type of volumes it provisions."))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Dynamic Volume Provisioning")),(0,o.kt)("p",null,"Many clusters also include ",(0,o.kt)("em",{parentName:"p"},"dynamic volume provisioning"),". With dynamic volume provisioning, the cluster operator creates one or more ",(0,o.kt)("inlineCode",{parentName:"p"},"StorageClass")," objects."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# a default storage class that automatically\n# provisions disk objects on the Microsoft Azure platform.\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: default\n  annotations:\n    storageclass.beta.kubernetes.io/is-default-class: 'true'\n  labels:\n    kubernetes.io/cluster-service: 'true'\nprovisioner: kubernetes.io/azure-disk\n")),(0,o.kt)("p",null,"Once a storage class has been created for a cluster, you can refer to this storage class in your persistent volume claim, rather than referring to any specific persistent volume."),(0,o.kt)("p",null,"When the dynamic provisioner sees this storage claim, it uses the appropriate volume driver to create the volume and bind it to your persistent volume claim."),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("p",null,"An example of a ",(0,o.kt)("inlineCode",{parentName:"p"},"PersistentVolumeClaim")," that uses the default storage class to claim a newly created persistent volume.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-claim\n  annotations:\n    # this links the claim back up to the storage class\n    volume.beta.kubernetes.io/storage-class: default\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n"))),(0,o.kt)("h2",{id:"statefulsets"},"StatefulSets"),(0,o.kt)("p",null,"However, some applications, especially stateful storage workloads or sharded applications, require more differentiation between the replicas in the application."),(0,o.kt)("p",null,"The purpose of ",(0,o.kt)("strong",{parentName:"p"},"StatefulSets")," is to provide some consistency and predictability to application deployments with stateful data."),(0,o.kt)("p",null,"In a ReplicaSet, each replicated Pod receives a name that involves a random hash (e.g., frontend-14a2), and there is no notion of ordering in a ReplicaSet. In contrast, with StatefulSets, each replica receives a monotonically increasing index (e.g., backend-0, backend-1, and so on)."),(0,o.kt)("p",null,"Further, StatefulSets guarantee that replica zero will be created and become healthy before replica one is created and so forth."),(0,o.kt)("p",null,"StatefulSets receive DNS names so that each replica can be accessed directly, in addition to the complete StatefulSet. This allows clients to easily target specific shards in a sharded service."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"This means that a Statefulset called db with 3 replicas will create the following pods:"),(0,o.kt)("pre",{parentName:"blockquote"},(0,o.kt)("code",{parentName:"pre"},"db-0\ndb-1\ndb-2\n"))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("p",null,"A stateful example")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'# a StorageClass kind of SSD drives in sea-central1-c\napiVersion: storage.k8s.io/v1beta1\nkind: StorageClass\nmetadata:\n  name: solidstate\nprovisioner: kubernetes.io/gce-pd\nparameters:\n  type: pd-ssd\n  zone: sea-central1-c\n\n# a StatefulSet with storage claims\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: whaleset\nspec:\n  serviceName: sayhey-svc\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: sayhey\n    spec:\n      terminationGracePeriodSeconds: 10\n      containers:\n        - name: sayhey\n          image: httpwhalesay:0.2\n          command: ["node", "index.js", "Whale it up!"]\n          ports:\n            - containerPort: 80\n              name: web\n          volumeMounts:\n            - name: www\n              mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n    - metadata:\n        name:         www\n        annotations:\n          volume.beta.kubernetes.io/storage-class: solidstate\n      spec:\n        accessModes: ["ReadWriteOnce"]\n        resources:\n          requests:\n            storage: 1Gi\n\n# service endpoint\napiVersion: v1\nkind: Service\nmetadata:\n  name: sayhey-svc\n  labels:\n    app: sayhey\nspec:\n  ports:\n    - port: 80\n      name: web\n  clusterIP: None\n  selector:\n    app: sayhey\n')),(0,o.kt)("p",null,"Using ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl get pv")," to show the PersistentVolumes."),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"kubectl get pvc")," to show the PersistentVolumesClaims.")),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("p",null,"Stateful Mongo Pods, automated initialization.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mongo\nspec:\n  serviceName: 'mongo'\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: mongo\n    spec:\n      containers:\n        - name: mongodb\n          image: mongodb:3.4.1\n          command:\n            - mongod\n            - --replSet\n            - rs0\n          ports:\n            - containerPort: 27017\n              name: peer\n")),(0,o.kt)("p",null,"Once the StatefulSet is created, we also need to create a \u201cheadless\u201d service to manage the DNS entries for the StatefulSet. In Kubernetes a service is called \u201cheadless\u201d if it doesn't have a cluster virtual IP address. Since with StatefulSets each Pod has a unique identity, it doesn't really make sense to have a load-balancing IP address for the replicated service. You can create a headless service using ",(0,o.kt)("inlineCode",{parentName:"p"},"clusterIP: None")," in the service specification."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Service\nmetadata:\n  name: mongo\nspec:\n  ports:\n    - port: 27017\n      name: peer\n  clusterIP: None\n  selector:\n    app: mongo\n")),(0,o.kt)("p",null,"Once you create that service, there are usually four DNS entries that are populated. As usual, ",(0,o.kt)("inlineCode",{parentName:"p"},"mongo.default.svc.cluster.local")," is created, but unlike with a standard service, doing a DNS lookup on this hostname provides all the addresses in the StatefulSet. In addition, entries are created for ",(0,o.kt)("inlineCode",{parentName:"p"},"mongo-0.mongo.default.svc.cluster.local")," as well as ",(0,o.kt)("inlineCode",{parentName:"p"},"mongo-1.mongo")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"mongo-2.mongo"),". Each of these resolves to the specific IP address of the replica index in the StatefulSet."),(0,o.kt)("p",null,"We\u2019ll choose ",(0,o.kt)("inlineCode",{parentName:"p"},"mongo-0.mongo")," to be our initial primary. Run the ",(0,o.kt)("inlineCode",{parentName:"p"},"mongo")," tool in that Pod:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'kubectl exec -it mongo-0 mongo\n\n# primary replica\n> rs.initiate( {\n    _id: "rs0",\n    members:[ { _id: 0, host: "mongo-0.mongo:27017" } ] });\n# OK\n\n# adding the remaining replicas\n> rs.add("mongo-1.mongo:27017");\n> rs.add("mongo-2.mongo:27017");\n')),(0,o.kt)("p",null,"However, we can automate the deployment of adding shards in the MongoDB by using an additional container in the Pods manifest to perform the initialization."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# refine the previous mongodb Pod manifest\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mongo\nspec:\n  serviceName: 'mongo'\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: mongo\n    spec:\n      containers:\n        - name: mongodb\n          image: mongodb:3.4.1\n          command:\n            - mongod\n            - --replSet\n            - rs0\n          ports:\n            - containerPort: 27017\n              name: web\n        - name: init-mongo\n          image: mongo:3.4.1\n          command:\n            - bash\n            - /config/init.sh\n          volumeMounts:\n            - name: config\n              mountPath: /config\n      volumes:\n        - name: config\n          configMap:\n            name: 'mongo-init'\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: mongo-init\ndata:\n  init.sh: |\n    #! /bin/bash\n\n    # Need to wait for the readiness health check to pass so that the\n    # mongo names resolve. This is kind of wonky.\n    until ping -c 1 ${HOSTNAME}.mongo; do\n      echo "waiting for DNS (${HOSTNAME}.mongo)..."\n      sleep 2\n    done\n\n    until /usr/bin/mongo --eval \'printjson(db.serverStatus())\'; do\n      echo "connecting to local mongo..."\n      sleep 2\n    done\n    echo "connected to local."\n\n    HOST=mongo-0.mongo.27017\n\n    until /usr/bin/mongo --host=${HOST} --eval \'printjson(db.serverStatus())\'; do\n      echo "connecting to remote mongo..."\n      sleep 2\n    done\n    echo "connected to remone."\n\n    if [[ "${HOSTNAME}" != \'mongo-0\' ]]; then\n      until /usr/bin/mongo --host=${HOST} --eval="printjson(rs.status())" \\\n            | grep -v "no replset config has been received"; do\n        echo "waiting for replication set initialization"\n        sleep 2\n      done\n\n      echo "adding self ${HOSTNAME} to ${HOST}"\n      /usr/bin/mongo --host=${HOST} \\\n          --eval="printjson(rs.add(\'${HOSTNAME}.mongo\'))"\n    fi\n\n    if [[ "${HOSTNAME}" == \'mongo-0\' ]]; then\n      echo "initializing replica set"\n      /usr/bin/mongo --eval="printjson(rs.initiate(\\\n        {\'_id\':\'rs0\', \'members\': [{ \'_id\': 0, \\\n         \'host\': \'mongo-0.mongo:27017\' }]}))"\n    fi\n    echo "initialized"\n\n    while true; do\n      sleep 3600\n    done\n')),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"This script (",(0,o.kt)("inlineCode",{parentName:"p"},"init.sh"),") currently sleeps forever after initializing the cluster. Every container in a Pod has to have the same RestartPolicy. Since we do not want our main Mongo container to be restarted, we need to have our initialization container run forever too, or else Kubernetes might think our Mongo Pod is unhealthy.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f mongo-config-map.yaml\nkubectl apply -f mongo-service.yaml\nkubectl apply -f mongo.yaml\n"))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Readiness Probe"),"Add liveness checks to the StatefulSet object",(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# ...\nlivenessProbe:\n  exec:\n    command:\n      - /usr/bin/mongo\n      - --eval\n      - db.serverStatus()\n  initialDelaySeconds: 10\n  timeoutSeconds: 10\n# ...\n"))),(0,o.kt)("h2",{id:"persistent-volumes-and-statefulsets"},"Persistent Volumes and StatefulSets"),(0,o.kt)("p",null,"For persistent storage, you need to mount a persistent volume into the ",(0,o.kt)("inlineCode",{parentName:"p"},"/data/db")," directory. In the Pod template, you need to update it to mount a persistent volume claim to that directory:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# ...\nvolumeMounts:\n  - name: database\n    mountPath: /data/db\n")),(0,o.kt)("p",null,"While this approach is similar to the one we saw with reliable singletons, because the StatefulSet replicates more than one Pod you cannot simply reference a persistent volume claim. Instead, you need to add a ",(0,o.kt)("em",{parentName:"p"},"persistent volume claim template"),"."),(0,o.kt)("p",null,"You need to add the following onto the bottom of your StatefulSet definition:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"volumeClaimTemplates:\n  - metadata:\n    name: database\n    annotations:\n      volume.alpha.kubernetes.io/storage-class: anything\n    spec:\n      accessModes: ['ReadWriteOnce']\n      resources:\n        requests:\n          storage: 100Gi\n")),(0,o.kt)("p",null,"When you add a volume claim template to a StatefulSet definition, each time the StatefulSet controller creates a Pod that is part of the StatefulSet it will create a persistent volume claim based on this template as part of that Pod."))}c.isMDXComponent=!0}}]);