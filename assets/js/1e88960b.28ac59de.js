"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[4602],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>h});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),m=c(a),u=i,h=m["".concat(l,".").concat(u)]||m[u]||d[u]||o;return a?n.createElement(h,r(r({ref:t},p),{},{components:a})):n.createElement(h,r({ref:t},p))}));function h(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=a.length,r=new Array(o);r[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[m]="string"==typeof e?e:i,r[1]=s;for(var c=2;c<o;c++)r[c]=a[c];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},80145:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var n=a(87462),i=(a(67294),a(3905));const o={title:"Docker",sidebar_position:2},r=void 0,s={unversionedId:"docker/docker",id:"docker/docker",title:"Docker",description:"Fun facts about images",source:"@site/docs/docker/docker.md",sourceDirName:"docker",slug:"/docker/",permalink:"/docs/docker/",draft:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"Docker",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Goroutines and the Go Runtime",permalink:"/docs/concurrency-in-go/internal"},next:{title:"Learn some Docker",permalink:"/docs/docker/"}},l={},c=[{value:"Fun facts about images",id:"fun-facts-about-images",level:2},{value:"Images - The commands",id:"images---the-commands",level:3},{value:"Fun facts about containers",id:"fun-facts-about-containers",level:2},{value:"Containerizing an app",id:"containerizing-an-app",level:2},{value:"Fun facts about Dockerfile",id:"fun-facts-about-dockerfile",level:2},{value:"Squashing",id:"squashing",level:3},{value:"Use no-install-recommends",id:"use-no-install-recommends",level:3},{value:"How Docker runs containers",id:"how-docker-runs-containers",level:2}],p={toc:c};function m(e){let{components:t,...a}=e;return(0,i.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"fun-facts-about-images"},"Fun facts about images"),(0,i.kt)("p",null,"A Docker image is physically stored as lots of small files, and Docker assembles them together to create the container\u2019s filesystem. When all the layers have been pulled, the full image is available to use."),(0,i.kt)("p",null,"A Docker image is a logical collection of image layers. Layers are the files that are physically stored in the Docker Engine\u2019s cache. Here\u2019s why that\u2019s important: image layers can be shared between different images and different containers."),(0,i.kt)("p",null,"If image layers are shared around, they can't be edited -- otherwise a change in one image would cascade to all the other images that share the changed layer. ",(0,i.kt)("em",{parentName:"p"},"Docker enforces that by making image layers read-only"),"."),(0,i.kt)("p",null,"In some ways, the image itself is just a configuration file that lists the layers and some metadata."),(0,i.kt)("p",null,"The layers are where the data lives (files and code etc.). Each layer is fully independent, and has no concept of being part of an overall bigger image. Each image is identified by a crypto ID that is a hash of the config file. Each layer is identified by a crypto ID that is a hash of the layer content. we call these \u201ccontent hashes\u201d."),(0,i.kt)("p",null,"Docker and Docker Hub have a slick way of supporting multi-arch images. This means a single image, such as golang:latest, can have an image for Linux on x64, Linux on PowerPC, Windows x64, Linux on different versions of ARM, and more. To make this happen, the Registry API supports two important constructs: ",(0,i.kt)("strong",{parentName:"p"},"manifest lists"),", ",(0,i.kt)("strong",{parentName:"p"},"manifests"),". The manifest list is exactly what it sounds like: a list of architectures supported by a particular image tag. Each supported architecture then has its own manifest detailing the layers that make it up."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"docker manifest inspect IMAGE\n\ndocker manifest inspect IMAGE | grep 'architecture\\|os'\n")),(0,i.kt)("h3",{id:"images---the-commands"},"Images - The commands"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"docker image pull")," is the command to download images. We pull images from repositories inside of remote registries. By default, images will be pulled from repositories on Docker Hub. This command will pull the image tagged as latest from the alpine repository on Docker Hub: ",(0,i.kt)("inlineCode",{parentName:"p"},"docker image pull alpine:latest"),".")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"docker image ls")," lists all images stored in your Docker host\u2019s local image cache. To see the SHA256 digests of images add the ",(0,i.kt)("inlineCode",{parentName:"p"},"--digests")," flag.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"docker image inspect")," is a thing of beauty! It gives you all glorious details of an image \u2014 layer data and metadata.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"docker manifest inspect")," allows you to inspect the manifest list of any image stored on Docker Hub. This will show the manifest list for the redis image: ",(0,i.kt)("inlineCode",{parentName:"p"},"docker manifest inspect redis"),".")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"docker buildx")," is a Docker CLI plugin that extends the Docker CLI to support multi-arch builds.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"docker image rm")," is the command to delete images. This command shows how to delete the alpine:latest image \u2014 ",(0,i.kt)("inlineCode",{parentName:"p"},"docker image rm alpine:latest"),". You cannot delete an image that is associated with a container in the running (Up) or stopped (Exited) states."))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# delete all images\ndocker image rm $(docker image ls -q) -f\n")),(0,i.kt)("h2",{id:"fun-facts-about-containers"},"Fun facts about containers"),(0,i.kt)("p",null,"Containers are running only while the application inside the container is running. As soon as the application process ends, the container goes into the exited state. Exited containers don't use any CPU time or memory. The interactive container we were connected to exited as soon as we exited the terminal application."),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Container exits when the main process in it exits.")),(0,i.kt)("p",null,"Containers don't disappear when they exit. Containers in the exited state still exist, which means you can start them again, check the logs, and copy files to and from the container\u2019s filesystem. You only see running containers with ",(0,i.kt)("inlineCode",{parentName:"p"},"docker container ls"),", but Docker doesn't remove exited containers unless you explicitly tell it to do so. Exited containers still take up space on disk because their filesystem is kept on the computer\u2019s disk."),(0,i.kt)("p",null,"Stopping a container does not destroy the container or the data inside of it."),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"docker container stop")," sends a ",(0,i.kt)("em",{parentName:"p"},"SIGTERM")," signal to the main application process inside the container. This gives the process a chance to clean things up and gracefully shut itself down. If it doesn't exit within 10 seconds, it will receive a ",(0,i.kt)("em",{parentName:"p"},"SIGKILL"),"."),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"docker container rm <container> -f")," only send ",(0,i.kt)("em",{parentName:"p"},"SIGKILL")," signal."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# delete all containers\ndocker container rm $(docker container ls -aq) -f\n")),(0,i.kt)("h2",{id:"containerizing-an-app"},"Containerizing an app"),(0,i.kt)("p",null,"The process of taking an application and configuring it to run as a container is called \u201ccontainerizing\u201d."),(0,i.kt)("p",null,"Containers are all about making apps simple to ",(0,i.kt)("em",{parentName:"p"},"build"),", ",(0,i.kt)("em",{parentName:"p"},"ship"),", and ",(0,i.kt)("em",{parentName:"p"},"run"),". The process of containerizing an app looks like this:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Start with the application code and dependencies.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Create a ",(0,i.kt)("em",{parentName:"p"},"Dockerfile")," that describes the app, its dependencies, and how to run it.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Feed the ",(0,i.kt)("em",{parentName:"p"},"Dockerfile")," into the ",(0,i.kt)("inlineCode",{parentName:"p"},"docker image build")," command.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Push the new image to a registry (optional)")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Run container from the image"))),(0,i.kt)("h2",{id:"fun-facts-about-dockerfile"},"Fun facts about Dockerfile"),(0,i.kt)("p",null,"Comment lines start with the ",(0,i.kt)("inlineCode",{parentName:"p"},"#")," character."),(0,i.kt)("p",null,"All non-comment lines are ",(0,i.kt)("strong",{parentName:"p"},"Instructions")," and take the format INSTRUCTION argument. Instruction names are not case-sensitive, but it\u2019s normal practice to write them in UPPERCASE. This makes reading the Dockerfile easier."),(0,i.kt)("p",null,"Some instructions create new layers, whereas others just add metadata to the image config file."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# show the build history\ndocker image history IMAGE\n")),(0,i.kt)("p",null,"A common example is that every ",(0,i.kt)("inlineCode",{parentName:"p"},"RUN")," instruction adds a new layer. As a result, it\u2019s usually considered a best practice to include multiple commands as part of a single ",(0,i.kt)("inlineCode",{parentName:"p"},"RUN")," instruction \u2014 all glued together with double-ampersands (&&) and backslash (",")"," line-breaks. While this isn't rocket science, it requires time and discipline."),(0,i.kt)("p",null,"This is called a ",(0,i.kt)("em",{parentName:"p"},"multi-stage")," Dockerfile, because there are several stages to the build. Each stage starts with a ",(0,i.kt)("inlineCode",{parentName:"p"},"FROM")," instruction, and you can optionally give stages a name with the AS parameter. Although there are multiple stages, the output will be a single Docker image with the contents of the ",(0,i.kt)("em",{parentName:"p"},"final stage"),"."),(0,i.kt)("p",null,"Each stage runs independently, but you can copy files and directories from previous stages."),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"RUN")," instruction executes a command inside a container during the build, and any output from that command is saved in the image layer. You can execute anything in a ",(0,i.kt)("inlineCode",{parentName:"p"},"RUN")," instruction, but the commands you want to run need to exist in the Docker image."),(0,i.kt)("p",null,"multi-stage mechanism provide us with:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("strong",{parentName:"p"},"standardization"),": this hugely simplifies on-boarding for new developers, eliminates the maintenance burden for build servers, and removes the potential for breakages where users have different versions of tools.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("strong",{parentName:"p"},"performance"),": Each stage in a multi-stage build has its own cache. Docker looks for a match in the image layer cache for each instruction; if it doesn't find one, the cache is broken and all the rest of the instructions are executed -- but only for that stage. The next stage starts again from the cache.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("strong",{parentName:"p"},"lightness"),": it helps to fine-tune your build so the final application image is as lean as possible. Any tooling you need can be isolated in earlier stages, so the tool itself isn't present in the final image."))),(0,i.kt)("details",null,(0,i.kt)("summary",null,"Specifying image labels ond build arguments in the Dockerfile"),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"LABEL")," instruction just applies the key/value pair from the Dockerfile to the image when it gets built."),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"ARG")," is very similar to the ",(0,i.kt)("inlineCode",{parentName:"p"},"ENV")," instruction, except that it works at build time on the image, rather than at run time in the container. They both set the value of an environment variable, but for ",(0,i.kt)("inlineCode",{parentName:"p"},"ARG")," instructions that setting only exists for the duration of the build, so any containers you run from the image don't see that variable."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-Dockerfile"},'# ...\nARG BUILD_NUMER=0\nARG BUILD_TAG=local\n\nLABEL version="3.0"\nLABEL build_number=${BUILD_NUMBER}\nLABEL build_tag=${BUILD_TAG}\n# ...\n'))),(0,i.kt)("details",null,(0,i.kt)("summary",null,"Any Dockerfile you write should be optimized so that the instructions are ordered by how frequently they change -- with instructions that are unlikely to change at the start of the Dockerfile, and instructions most likely to change at the end."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-Dockerfile"},'FROM diamol/node\n\nENV TARGET="blog.sixeyed.com"\nENV METHOD="HEAD"\nENV INTERVAL="3000"\n\nWORKDIR /web-ping\nCOPY app.js ./\n\nCMD ["node", "/web-ping/app.js"]\n')),(0,i.kt)("p",null,"The above docker would generate 7 layers, and when the ",(0,i.kt)("inlineCode",{parentName:"p"},"app.js")," file change, the last layer also will rebuild even though its content doesn't change."),(0,i.kt)("p",null,"The following docker has 5 layers, and only the last layer would rebuild when the ",(0,i.kt)("inlineCode",{parentName:"p"},"app.js")," is modified."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-Dockerfile"},'FROM diamol/node\n\nCMD ["node", "/web-ping/app.js"]\n\nENV TARGET="blog.sixeyed.com" \\\n    METHOD="HEAD" \\\n    INTERVAL="3000"\n\nWORKDIR /web-ping\nCOPY app.js .\n'))),(0,i.kt)("h3",{id:"squashing"},"Squashing"),(0,i.kt)("p",null,"Squashing can be good in situations where images are starting to have a lot of layers and this isn't ideal. An example might be when creating a new base image that you want to build other images from in the future \u2014 this base is much better as a single-layer image."),(0,i.kt)("p",null,"On the negative side, squashed images do not share image layers. This can result in storage inefficiencies and larger push and pull operations."),(0,i.kt)("p",null,"Add the ",(0,i.kt)("inlineCode",{parentName:"p"},"--squash")," flag to the ",(0,i.kt)("inlineCode",{parentName:"p"},"docker image build")," command if you want to create a squashed image."),(0,i.kt)("h3",{id:"use-no-install-recommends"},"Use no-install-recommends"),(0,i.kt)("p",null,"If you are building Linux images, and using the apt package manager, you should use the ",(0,i.kt)("inlineCode",{parentName:"p"},"no-install-recommends")," flag with the ",(0,i.kt)("inlineCode",{parentName:"p"},"apt-get install")," command. This makes sure that apt only installs main dependencies (packages in the Depends field) and not recommended or suggested packages. This can greatly reduce the number of unwanted packages that are downloaded into your images."),(0,i.kt)("h2",{id:"how-docker-runs-containers"},"How Docker runs containers"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"The Docker Engine is the management component of Docker. It looks after the local image cache, downloading images when you need them, and reusing them if they\u2019re already downloaded. It also works with the operating system to create containers, virtual networks, and all the other Docker resources. The Engine is a background process that is always running.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"The Docker Engine makes all the features available through the Docker API, which is just a standard HTTP-based REST API. You can configure the Engine to make the API accessible only from the local computer (which is the default), or make it available to other remote computers on your network.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"The Docker command-line interface (CLI) is a client of the Docker API. When you run Docker commands, the CLI actually sends them to the Docker API, and the Docker Engine does the work."))),(0,i.kt)("p",null,"The Docker Engine uses a component called ",(0,i.kt)("inlineCode",{parentName:"p"},"containerd")," to actually manage containers, and ",(0,i.kt)("em",{parentName:"p"},"containerd")," in turn makes use of operating system features to create the virtual environment that is the container."),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Internally, the daemon instructed ",(0,i.kt)("inlineCode",{parentName:"p"},"containerd")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"runc")," to create and start the container.")),(0,i.kt)("p",null,"Restart policies are applied per-container, and can be configured imperatively on the command line as part of ",(0,i.kt)("inlineCode",{parentName:"p"},"docker-container run")," commands, or declarative in YAML files for use with higher-level tools such as Docker Swarm, Docker Compose, and Kubernetes."),(0,i.kt)("p",null,"There are three kinds of restart policies:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"always"),(0,i.kt)("li",{parentName:"ul"},"unless-stopped"),(0,i.kt)("li",{parentName:"ul"},"on-failed")),(0,i.kt)("p",null,"The ",(0,i.kt)("em",{parentName:"p"},"always")," policy is the simplest. It always restarts a stopped container unless it has been explicitly stopped, such as via a ",(0,i.kt)("inlineCode",{parentName:"p"},"docker container stop")," command."),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"An interesting feature of the ",(0,i.kt)("inlineCode",{parentName:"p"},"--restart always")," policy is that if you stop a container with ",(0,i.kt)("inlineCode",{parentName:"p"},"docker container stop")," and the restart the Docker daemon, the container will be restarted. To be clear... you start a new container with the ",(0,i.kt)("inlineCode",{parentName:"p"},"--restart always")," policy and then stop it with the docker container stop command. At this point the container is in the Stopped (Exited) state. However, if you restart the Docker daemon, the container will be automatically restarted when the daemon comes back up. You need to be aware of this.")),(0,i.kt)("p",null,"The main difference between the ",(0,i.kt)("em",{parentName:"p"},"always")," and ",(0,i.kt)("em",{parentName:"p"},"unless-stopped")," policies is that containers with the ",(0,i.kt)("inlineCode",{parentName:"p"},"--restart unless-stopped")," policy will ",(0,i.kt)("em",{parentName:"p"},"not be restarted")," when the daemon restarts if they were in the Stopped (Exited) state."),(0,i.kt)("p",null,"The ",(0,i.kt)("em",{parentName:"p"},"on-failure")," policy will restart a container if it exits with a non-zero exit code. It will also restart containers when the Docker daemon restarts, even containers that were in the stopped state."),(0,i.kt)("p",null,"Publishing ports needs a little more explanation. When you install Docker, it injects itself into your computer\u2019s networking layer. Traffic coming into your computer can be intercepted by Docker, and then Docker can send that traffic into a container."))}m.isMDXComponent=!0}}]);