"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[425],{3905:(e,n,t)=>{t.d(n,{Zo:()=>m,kt:()=>u});var r=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function s(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?s(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},s=Object.keys(e);for(r=0;r<s.length;r++)t=s[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)t=s[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var i=r.createContext({}),p=function(e){var n=r.useContext(i),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},m=function(e){var n=p(e.components);return r.createElement(i.Provider,{value:n},e.children)},f="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},c=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,s=e.originalType,i=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),f=p(t),c=a,u=f["".concat(i,".").concat(c)]||f[c]||d[c]||s;return t?r.createElement(u,o(o({ref:n},m),{},{components:t})):r.createElement(u,o({ref:n},m))}));function u(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var s=t.length,o=new Array(s);o[0]=c;var l={};for(var i in n)hasOwnProperty.call(n,i)&&(l[i]=n[i]);l.originalType=e,l[f]="string"==typeof e?e:a,o[1]=l;for(var p=2;p<s;p++)o[p]=t[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,t)}c.displayName="MDXCreateElement"},12829:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>o,default:()=>f,frontMatter:()=>s,metadata:()=>l,toc:()=>p});var r=t(87462),a=(t(67294),t(3905));const s={title:"09",tags:["lisp","interpreter"]},o=void 0,l={unversionedId:"lisp-interpreter-in-py/chapter-09",id:"lisp-interpreter-in-py/chapter-09",title:"09",description:"Here is what we're going to go through:",source:"@site/docs/lisp-interpreter-in-py/chapter-09.md",sourceDirName:"lisp-interpreter-in-py",slug:"/lisp-interpreter-in-py/chapter-09",permalink:"/docs/lisp-interpreter-in-py/chapter-09",draft:!1,tags:[{label:"lisp",permalink:"/docs/tags/lisp"},{label:"interpreter",permalink:"/docs/tags/interpreter"}],version:"current",frontMatter:{title:"09",tags:["lisp","interpreter"]},sidebar:"tutorialSidebar",previous:{title:"08",permalink:"/docs/lisp-interpreter-in-py/chapter-08"},next:{title:"10",permalink:"/docs/lisp-interpreter-in-py/chapter-10"}},i={},p=[],m={toc:p};function f(e){let{components:n,...t}=e;return(0,a.kt)("wrapper",(0,r.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Here is what we're going to go through:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"How to parse and interpret a Pascal program definiton"),(0,a.kt)("li",{parentName:"ol"},"How to parse and interpret compound statements"),(0,a.kt)("li",{parentName:"ol"},"How to parse and interpret assignment statements, including variables"),(0,a.kt)("li",{parentName:"ol"},"A bit about symbol tables and how to store and lookup variables.")),(0,a.kt)("p",null,"The following sample Pascal-like program to introduce new concepts:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"# Pascal-like\nBEGIN\n    BEGIN\n        number := 2;\n        a := number;\n        b := 10 * a + 10 * number / 4;\n        c := a - - b\n    END;\n    x := 11;\nEND.\n")),(0,a.kt)("p",null,"Let's dive in and look at syntax diagrams for new language constructs and their corresponding grammar rules."),(0,a.kt)("img",{src:"./imgs/lsbasi_part9_syntax_diagram.png",alt:""}),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"A Pascal ",(0,a.kt)("em",{parentName:"p"},"program")," consists of a ",(0,a.kt)("em",{parentName:"p"},"compound statement")," that ends with a dot. Here is an example of a program (this is not a complete program definition, and we'll extend it later in the series):"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"BEGIN END.\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"A ",(0,a.kt)("em",{parentName:"p"},"compound statement")," is a block marked with ",(0,a.kt)("inlineCode",{parentName:"p"},"BEGIN")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"END")," that can contain a list (possibly empty) of statements including other compound statements. Every statement inside the compound statement, except for the last one, must terminate with a semicolon. The last statement in the block may or may not have a terminating semicolon:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"BEGIN END\nBEGIN a := 5; x := 11 END\nBEGIN a := 5; x := 11; END\nBEGIN BEGIN a := 5 END; x := 11 END\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"A ",(0,a.kt)("em",{parentName:"p"},"statement list")," is a list of zero or more statements inside a compound statement.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"A ",(0,a.kt)("em",{parentName:"p"},"statement")," can be a ",(0,a.kt)("em",{parentName:"p"},"compound statement"),", an ",(0,a.kt)("em",{parentName:"p"},"assignment statement"),", or it can be an ",(0,a.kt)("em",{parentName:"p"},"empty statement"),".")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"An ",(0,a.kt)("em",{parentName:"p"},"assignment statement")," is a variable followed by an ASSIGN token ",(0,a.kt)("inlineCode",{parentName:"p"},":="),", followed by an expression."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"a := 11\nb := a + 9 - 5 * 2\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"A ",(0,a.kt)("em",{parentName:"p"},"variable")," is an identifier. We use the ID token for variables. The value of the token will be a variable's name like ",(0,a.kt)("inlineCode",{parentName:"p"},"a"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," and so on."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"BEGIN a := 11; b := a + 9; END\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"An ",(0,a.kt)("em",{parentName:"p"},"empty statement")," represents a grammar rule with no further productions. We use the ",(0,a.kt)("em",{parentName:"p"},"empty_statement")," grammar rule to indicate the end of the ",(0,a.kt)("em",{parentName:"p"},"statement_list")," in the parser and to allow for empty compound statement as in ",(0,a.kt)("inlineCode",{parentName:"p"},"BEGIN END"),".")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The ",(0,a.kt)("em",{parentName:"p"},"factor")," rule is updated to handle variables."))),(0,a.kt)("p",null,"Now let's take a looke at our complete grammar:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"program : compound_statement DOT\n\ncompound_statement : BEGIN statement_list END\n\nstatement_list : statement\n                | statement SEMI statement_list\n\nstatement : compound_statement\n            | assignment_statement\n            | empty\n\nassignment_statement : variable ASSIGN expr\n\nempty :\n\nexpr: term ((PLUS | MINUS) term)*\n\nterm: factor ((MUL | DIV) factor)*\n\nfactor : PLUS factor\n        | MINUS factor\n        | INTEGER\n        | LPAREN expr RPAREN\n        | variable\n\nvariable: ID\n")),(0,a.kt)("p",null,"You probably noticed that we don't use the star '",(0,a.kt)("em",{parentName:"p"},"' symbol in the "),"compound_statement",(0,a.kt)("em",{parentName:"p"}," rule to represent zero or more repetitions, but instead explicitly specified the "),"statement_list","*"," rule. This is another way to represent the 'zero or more' operation, and it will come in handy when we look at parser generators like ",(0,a.kt)("a",{parentName:"p",href:"http://www.dabeaz.com/ply/"},"PLY"),", later in the series. We'll also split the \u201c(PLUS | MINUS) factor\u201d sub-rule into two separate rules."),(0,a.kt)("p",null,"In order to support the updated grammar, we need to make a number of changes to our lexer, parser, and interpreter. Let's go over those changes one by one."),(0,a.kt)("p",null,"Here is the summary of the changes in our lexer:"),(0,a.kt)("img",{src:"./imgs/lsbasi_part9_lexer.png",alt:""}),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"To support a Pascal program's definition, compound statements, assignment statements, and variables, our lexer needs to return new tokens:"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"BEGIN (to mark the beginning of a compound statement)"),(0,a.kt)("li",{parentName:"ul"},"END (to mark the end of the compound statement)"),(0,a.kt)("li",{parentName:"ul"},"DOT (a token for a dot character '.' required by a Pascal program's definition)"),(0,a.kt)("li",{parentName:"ul"},"ASSIGN (a token for a two character sequence ':='). In Pascal, an assignment operator is different from in many other languages like C, Python, Java, Rust, or Go, where you would use single character '=' to indicate assignment"),(0,a.kt)("li",{parentName:"ul"},"SEMI (a token for a semicolon character ';' that is used to mark the end of a statement inside a compound statement)"),(0,a.kt)("li",{parentName:"ul"},"ID (A token for a valid identifier. Identifiers start with an alphabetical character followed by any number of alphanumerical characters)"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Sometimes, in order to be able to differentiate between different tokens that start with the same character, (':' vs ':=' or '==' vs '=>' ) we need to peek into the input buffer without actually consuming the next character. For this particular purpose, We introduced a ",(0,a.kt)("em",{parentName:"p"},"peek")," method that will help us tokenize assignment statements. The method is not strictly required, but it will also make the ",(0,a.kt)("em",{parentName:"p"},"get_next_token")," method a bit cleaner if we introduce it earlier in the series. All it does is return the next character from the text buffer without incrementing the ",(0,a.kt)("em",{parentName:"p"},"self.pos")," variable. Here is the method itself:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def peek(self):\n    peek_pos = self.pos + 1\n    if peek_pos > len(self.text) - 1:\n        return None\n    else:\n        return self.text[peek_pos]\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Because Pascal variables and reserved keywords are both identifiers, we will combine their handling into one method called ",(0,a.kt)("em",{parentName:"p"},"_","id"),". The way it works is that the lexer consumes a sequence of alphanumerical characters and then checks if the character sequence is a reserved word. If it is, it returns a pre-constructed token for that reserved keyword. And if it's not a reserved keyword, it returns a new ID token whose value is the character string (lexeme)."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-python"},"RESERVED_KEYWORDS = {\n    'BEGIN': Token('BEGIN', 'BEGIN'),\n    'END': Token('END', 'END'),\n}\n\ndef _id(self):\n    \"\"\" Handle indentifiers and reserved keywords \"\"\"\n    result = ''\n    while self.current_char is not None and self.current_char.isalnum():\n        result += self.current_char\n        self.advance()\n\n    token = RESERVED_KEYWORDS.get(result, Token(ID, result))\n    return token\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"And now let's take a look at the changes in the main lexer method ",(0,a.kt)("em",{parentName:"p"},"get_next_token"),":"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def get_next_token(self):\n    while self.current_char is not None:\n        ...\n        if self.current_char.isalpha():\n            return self._id()\n\n        if self.current_char == ':' and self.peek() == '=':\n            self.advance()\n            self.advance()\n            return Token(ASSIGN, ':=')\n\n        if self.current_char == ';':\n            self.advance()\n            return Token(SEMI, ';')\n\n        if self.current_char == '.':\n            self.advance()\n            return Token(DOT, '.')\n        ...\n")))),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Appendix")),(0,a.kt)("p",null,"And the complete code:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'""" SPI - Simple Pascal Interpreter. Part 9."""\n\n###############################################################################\n#                                                                             #\n#  LEXER                                                                      #\n#                                                                             #\n###############################################################################\n\n# Token types\n#\n# EOF (end-of-file) token is used to indicate that\n# there is no more input left for lexical analysis\n\n(INTEGER, PLUS, MINUS, MUL, DIV, LPAREN, RPAREN, ID, ASSIGN,\n BEGIN, END, SEMI, DOT, EOF) = (\n    \'INTEGER\', \'PLUS\', \'MINUS\', \'MUL\', \'DIV\', \'(\', \')\', \'ID\', \'ASSIGN\',\n    \'BEGIN\', \'END\', \'SEMI\', \'DOT\', \'EOF\'\n)\n\n\nclass Token(object):\n    def __init__(self, type, value):\n        self.type = type\n        self.value = value\n\n    def __str__(self):\n        """String representation of the class instance.\n        Examples:\n            Token(INTEGER, 3)\n            Token(PLUS, \'+\')\n            Token(MUL, \'*\')\n        """\n        return \'Token({type}, {value})\'.format(\n            type=self.type,\n            value=repr(self.value)\n        )\n\n    def __repr__(self):\n        return self.__str__()\n\n\nRESERVED_KEYWORDS = {\n    \'BEGIN\': Token(\'BEGIN\', \'BEGIN\'),\n    \'END\': Token(\'END\', \'END\'),\n}\n\n\nclass Lexer(object):\n    def __init__(self, text):\n        # client string input, e.g. "4 + 2 * 3 - 6 / 2"\n        self.text = text\n        # self.pos is an index into self.text\n        self.pos = 0\n        self.current_char = self.text[self.pos]\n\n    def error(self):\n        raise Exception(\'Invalid character\')\n\n    def advance(self):\n        """Advance the `pos` pointer and set the `current_char` variable."""\n        self.pos += 1\n        if self.pos > len(self.text) - 1:\n            self.current_char = None  # Indicates end of input\n        else:\n            self.current_char = self.text[self.pos]\n\n    def peek(self):\n        peek_pos = self.pos + 1\n        if peek_pos > len(self.text) - 1:\n            return None\n        else:\n            return self.text[peek_pos]\n\n    def skip_whitespace(self):\n        while self.current_char is not None and self.current_char.isspace():\n            self.advance()\n\n    def integer(self):\n        """Return a (multidigit) integer consumed from the input."""\n        result = \'\'\n        while self.current_char is not None and self.current_char.isdigit():\n            result += self.current_char\n            self.advance()\n        return int(result)\n\n    def _id(self):\n        """Handle identifiers and reserved keywords"""\n        result = \'\'\n        while self.current_char is not None and self.current_char.isalnum():\n            result += self.current_char\n            self.advance()\n\n        token = RESERVED_KEYWORDS.get(result, Token(ID, result))\n        return token\n\n    def get_next_token(self):\n        """Lexical analyzer (also known as scanner or tokenizer)\n        This method is responsible for breaking a sentence\n        apart into tokens. One token at a time.\n        """\n        while self.current_char is not None:\n\n            if self.current_char.isspace():\n                self.skip_whitespace()\n                continue\n\n            if self.current_char.isalpha():\n                return self._id()\n\n            if self.current_char.isdigit():\n                return Token(INTEGER, self.integer())\n\n            if self.current_char == \':\' and self.peek() == \'=\':\n                self.advance()\n                self.advance()\n                return Token(ASSIGN, \':=\')\n\n            if self.current_char == \';\':\n                self.advance()\n                return Token(SEMI, \';\')\n\n            if self.current_char == \'+\':\n                self.advance()\n                return Token(PLUS, \'+\')\n\n            if self.current_char == \'-\':\n                self.advance()\n                return Token(MINUS, \'-\')\n\n            if self.current_char == \'*\':\n                self.advance()\n                return Token(MUL, \'*\')\n\n            if self.current_char == \'/\':\n                self.advance()\n                return Token(DIV, \'/\')\n\n            if self.current_char == \'(\':\n                self.advance()\n                return Token(LPAREN, \'(\')\n\n            if self.current_char == \')\':\n                self.advance()\n                return Token(RPAREN, \')\')\n\n            if self.current_char == \'.\':\n                self.advance()\n                return Token(DOT, \'.\')\n\n            self.error()\n\n        return Token(EOF, None)\n\n\n###############################################################################\n#                                                                             #\n#  PARSER                                                                     #\n#                                                                             #\n###############################################################################\n\nclass AST(object):\n    pass\n\n\nclass BinOp(AST):\n    def __init__(self, left, op, right):\n        self.left = left\n        self.token = self.op = op\n        self.right = right\n\n\nclass Num(AST):\n    def __init__(self, token):\n        self.token = token\n        self.value = token.value\n\n\nclass UnaryOp(AST):\n    def __init__(self, op, expr):\n        self.token = self.op = op\n        self.expr = expr\n\n\nclass Compound(AST):\n    def __init__(self):\n        self.children = []\n\n\nclass Assign(AST):\n    def __init__(self, left, op, right):\n        self.left = left\n        self.token = self.op = op\n        self.right = right\n\n\nclass Var(AST):\n    """ The Var node is constructed out of ID token. """\n\n    def __init__(self, token):\n        self.token = token\n        self.value = token.value\n\n\nclass NoOp(AST):\n    pass\n\n\nclass Parser(object):\n    def __init__(self, lexer):\n        self.lexer = lexer\n        # set current token to the first token taken from the input\n        self.current_token = self.lexer.get_next_token()\n\n    def error(self):\n        raise Exception(\'Invalid syntax\')\n\n    def eat(self, token_type):\n        # compare the current token type with the passed token\n        # type and if they match then "eat" the current token\n        # and assign the next token to the self.current_token,\n        # otherwise raise an exception.\n        if self.current_token.type == token_type:\n            self.current_token = self.lexer.get_next_token()\n        else:\n            self.error()\n\n    def program(self):\n        """ program : compound_statement DOT """\n        node = self.compound_statement()\n        self.eat(DOT)\n        return node\n\n    def compound_statement(self):\n        """\n        compound_statement: BEGIN statement_list END\n        """\n        self.eat(BEGIN)\n        nodes = self.statement_list()\n        self.eat(END)\n\n        root = Compound()\n        for node in nodes:\n            root.children.append(node)\n\n        return root\n\n    def statement_list(self):\n        """\n        statement_list : statement\n                       | statement SEMI statement_list\n        """\n        node = self.statement()\n\n        results = [node]\n\n        while self.current_token.type == SEMI:\n            self.eat(SEMI)\n            results.append(self.statement())\n\n        if self.current_token.type == ID:\n            self.error()\n\n        return results\n\n    def statement(self):\n        """\n        statement : compound_statement\n            | assignment_statement\n            | empty\n        """\n        if self.current_token.type == BEGIN:\n            node = self.compound_statement()\n        elif self.current_token.type == ID:\n            node = self.assignment_statement()\n        else:\n            node = self.empty()\n\n        return node\n\n    def assignment_statement(self):\n        """\n        assignment_statement: variable ASSIGN expr\n        """\n        left = self.variable()\n        token = self.current_token\n        self.eat(ASSIGN)\n        right = self.expr()\n        node = Assign(left, token, right)\n        return node\n\n    def variable(self):\n        """\n        variable : ID\n        """\n        node = Var(self.current_token)\n        self.eat(ID)\n        return node\n\n    def empty(self):\n        """ An empty production"""\n        return NoOp()\n\n    def expr(self):\n        """\n        expr : term ((PLUS | MINUS))*\n        """\n\n        node = self.term()\n        while self.current_token.type in (PLUS, MINUS):\n            token = self.current_token\n            if token.type == PLUS:\n                self.eat(PLUS)\n            elif token.type == MINUS:\n                self.eat(MINUS)\n\n            node = BinOp(left=node, op=token, right=self.term())\n        return node\n\n    def term(self):\n        """ term : factor ((MUL | DIV) factor)* """\n        node = self.factor()\n\n        while self.current_token.type in (MUL, DIV):\n            token = self.current_token\n            if token.type == MUL:\n                self.eat(MUL)\n            elif token.type == DIV:\n                self.eat(DIV)\n\n            node = BinOp(left=node, op=token, right=self.factor())\n\n        return node\n\n    def factor(self):\n        """ factor : PLUS factor\n                   | MINUS factor\n                   | INTEGER\n                   | LPAREN expr RPAREN\n                   | variable\n        """\n        token = self.current_token\n        if token.type == PLUS:\n            self.eat(PLUS)\n            node = UnaryOp(token, self.factor())\n            return node\n        elif token.type == MINUS:\n            self.eat(MINUS)\n            node = UnaryOp(token, self.factor())\n            return node\n        elif token.type == INTEGER:\n            self.eat(INTEGER)\n            return Num(token)\n        elif token.type == LPAREN:\n            self.eat(LPAREN)\n            node = self.expr()\n            self.eat(RPAREN)\n            return node\n        else:\n            node = self.variable()\n            return node\n\n    def parse(self):\n        """\n        program : compound_statement DOT\n        compound_statement : BEGIN statement_list END\n        statement_list : statement\n                       | statement SEMI statement_list\n        statement : compound_statement\n                  | assignment_statement\n                  | empty\n        assignment_statement : variable ASSIGN expr\n        empty :\n        expr: term ((PLUS | MINUS) term)*\n        term: factor ((MUL | DIV) factor)*\n        factor : PLUS factor\n               | MINUS factor\n               | INTEGER\n               | LPAREN expr RPAREN\n               | variable\n        variable: ID\n        """\n        node = self.program()\n        if self.current_token.type != EOF:\n            self.error()\n\n        return node\n\n\n###############################################################################\n#                                                                             #\n#  INTERPRETER                                                                #\n#                                                                             #\n###############################################################################\n\n\nclass NodeVisitor(object):\n    def visit(self, node):\n        method_name = \'visit_\' + type(node).__name__\n        visitor = getattr(self, method_name, self.generic_visit)\n        return visitor(node)\n\n    def generic_visit(self, node):\n        raise Exception(\'No visit_{} method\'.format(type(node).__name__))\n\n\nclass Interpreter(NodeVisitor):\n    GLOBAL_SCOPE = {}\n\n    def __init__(self, parser):\n        self.parser = parser\n\n    def visit_BinOp(self, node):\n        if node.op.type == PLUS:\n            return self.visit(node.left) + self.visit(node.right)\n        elif node.op.type == MINUS:\n            return self.visit(node.left) - self.visit(node.right)\n        elif node.op.type == MUL:\n            return self.visit(node.left) * self.visit(node.right)\n        elif node.op.type == DIV:\n            return self.visit(node.left) / self.visit(node.right)\n\n    def visit_Num(self, node):\n        return node.value\n\n\n    def visit_UnaryOp(self, node):\n        op = node.op.type\n        if op == PLUS:\n            return +self.visit(node.expr)\n        elif op == MINUS:\n            return -self.visit(node.expr)\n\n    def visit_Compound(self, node):\n        for child in node.children:\n            self.visit(child)\n\n    def visit_Assign(self, node):\n        var_name = node.left.value\n        self.GLOBAL_SCOPE[var_name] = self.visit(node.right)\n\n    def visit_Var(self, node):\n        var_name = node.value\n        val = self.GLOBAL_SCOPE.get(var_name)\n        if val is None:\n            raise NameError(repr(var_name))\n        else:\n            return val\n\n    def visit_NoOp(self, node):\n        pass\n\n    def interpret(self):\n        tree = self.parser.parse()\n        if tree is None:\n            return \'\'\n        return self.visit(tree)\n\ndef main():\n    import sys\n    text = open(sys.argv[1], \'r\').read()\n\n    lexer = Lexer(text)\n    parser = Parser(lexer)\n    interpreter = Interpreter(parser)\n    result = interpreter.interpret()\n    print(interpreter.GLOBAL_SCOPE)\n\n\nif __name__ == \'__main__\':\n    main()\n')),(0,a.kt)("p",null,"Moving on to parser changes."),(0,a.kt)("p",null,"Here is the summary of changes in the parser:"),(0,a.kt)("img",{src:"./imgs/lsbasi_part9_parser.png",alt:""}),(0,a.kt)("p",null,"1.Let's start with new AST nodes:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Compound AST node represents a compound statement. It contains a list of statement nodes in its ",(0,a.kt)("inlineCode",{parentName:"li"},"children")," variable.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'class Compound(AST):\n    """ Represents a \'BEGIN ... END\' block """\n    def __init__self():\n        self.children = []\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Assign AST node represents an assignment statement. Its ",(0,a.kt)("inlineCode",{parentName:"li"},"left")," variable is for storing a ",(0,a.kt)("em",{parentName:"li"},"Var")," node and its ",(0,a.kt)("inlineCode",{parentName:"li"},"right")," variable for a node returned by the ",(0,a.kt)("em",{parentName:"li"},"expr")," parser method:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"class Assign(AST):\n    def __init__(self, left, op , right):\n        self.left = left\n        self.token = self.op = op\n        self.right = right\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("em",{parentName:"li"},"NoOp")," node is used to represent an empty statement. For example ",(0,a.kt)("inlineCode",{parentName:"li"},"BEGIN END")," is a valid compound statement that has no statements.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"class NoOp(AST):\n    pass\n")),(0,a.kt)("p",null,"2.Each rule from the grammar has a corresponding method in the recursive-descent parser. This time we add some methods which are responsible for parsing new language constructs and constructing new AST nodes. They are pretty straightforward:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def program(self):\n    """ program : compound_statement DOT """\n    node = self.coumpound_statement()\n    self.eat(DOT)\n    return node\n\ndef compound_statement(self):\n    """\n    compound_statement: BEGIN statement_list END\n    """\n    self.eat(BEGIN)\n    nodes = self.statement_list()\n    self.eat(END)\n\n    root = Compound()\n    for node in nodes:\n        root.children.append(node)\n\n    return root\n\ndef statement_list(self):\n    """\n    statement_list : statement\n                   | statement SEMI statement_list\n    """\n    node = self.statement()\n\n    results = [node]\n\n    while self.current_token.type == SEMI:\n        self.eat(SEMI)\n        results.append(self.statement())\n\n    if self.current_token.type == ID:\n        self.error()\n\n    return results\n\ndef statement(self):\n    """\n    statement : compound_statement\n              | assignment_statement\n              | empty\n    """\n    if self.current_token.type == BEGIN:\n        node = self.compound_statement()\n    elif self.current_token.type == ID:\n        node = self.assignment_statement()\n    else:\n        node = self.empty()\n\n    return node\n\ndef assign_statement(self):\n    """\n    assignment_statement : variable ASSIGN expr\n    """\n    left = self.variable()\n    token = self.current_token\n    self.eat(ASSIGN)\n    right = self.expr()\n    node = Assign(left, token, right)\n    return node\n\ndef variable(self):\n    """\n    variable: ID\n    """\n    node = Var(self.current_token)\n    self.eat(ID)\n    return node\n\ndef empty(self):\n    """ An empty production """\n    return NoOp()\n')),(0,a.kt)("p",null,"3.We also need to update the existing ",(0,a.kt)("em",{parentName:"p"},"factor")," method to parse variables:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def factor(self):\n    """\n    factor : PLUS factor\n           | MINUS factor\n           | INTEGER\n           | LPAREN expr RPAREN\n           | variable\n    """\n    token = self.current_token\n    if token.type == PLUS:\n        self.eat(PLUS)\n        node = UnaryOp(token, self.factor())\n        return node\n    ...\n    else:\n        node = self.variable()\n        return node\n')),(0,a.kt)("p",null,"4.The parser's ",(0,a.kt)("em",{parentName:"p"},"parse")," method is updated to start the parsing process by parsing a program definition;"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def parse(self):\n    node = self.program()\n    if self.current_token.type != EOF:\n        self.error()\n\n    return node\n")),(0,a.kt)("p",null,"And some changes are required for the interpreter:"),(0,a.kt)("img",{src:"./imgs/lsbasi_part9_interpreter.png",alt:""}),(0,a.kt)("p",null,"To interpreter new AST nodes, we need to add corresponding visitor methods to the interpreter."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"visit_Compound"),(0,a.kt)("li",{parentName:"ul"},"visit_Assign"),(0,a.kt)("li",{parentName:"ul"},"visit_Var"),(0,a.kt)("li",{parentName:"ul"},"visit_NoOp")),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},"Compound")," and ",(0,a.kt)("em",{parentName:"p"},"NoOp")," visitor methods are pretty straightforward. The ",(0,a.kt)("em",{parentName:"p"},"visit_Compound")," method iterates over its children and visits each one in turn, and the ",(0,a.kt)("em",{parentName:"p"},"visit_NoOp")," method does nothing."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def visit_Compound(self, node):\n    for child in node.children:\n        self.visit(child)\n\ndef visit_NoOp(self, node):\n    pass\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("em",{parentName:"p"},"Assign")," and ",(0,a.kt)("em",{parentName:"p"},"Var")," visitor methods deserve a closer examination."),(0,a.kt)("p",null,"When we assign a value to a variable, we need to store that value somewhere for when we need it later, and that's exactly what the ",(0,a.kt)("em",{parentName:"p"},"visit_Assign")," method does:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def visit_Assign(self, node):\n    var_name = node.left.value\n    self.GLOBAL_SCOPE[var_name] = self.visit(node.right)\n")),(0,a.kt)("p",null,"The method stores a key-value pair in a ",(0,a.kt)("em",{parentName:"p"},"symbol table")," GLOBAL_SCOPE, which is an abstract data type (ADT) for tracking various symbols in source code. The only symbol category we have right now is variables and we use the Python dictionary to implement the symbol table ADT."),(0,a.kt)("p",null,'Let\'s take a look at an AST for the statement "a := 3;" and the symbol table before and after the ',(0,a.kt)("em",{parentName:"p"},"visit_Assign")," method does its job:"),(0,a.kt)("img",{src:"./imgs/lsbasi_part9_ast_st01.png",alt:""}),(0,a.kt)("p",null,'Then take a look at an AST for the statement "b := a + 7;"'),(0,a.kt)("img",{src:"./imgs/lsbasi_part9_ast_only_st02.png",alt:""}),(0,a.kt)("p",null,"The right-hand side of the assignment statement - \"a + 7\" -references the variable 'a', so we need to find out what the value 'a' is before we can evaluate the expression \"a + 7\", which is the responsibility of the ",(0,a.kt)("em",{parentName:"p"},"visit_Var")," method:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def visit_Var(self,node):\n    var_name = node.value\n    val = self.GLOBAL_SCOPE.get(var_name)\n    if val is None:\n        raise NameError(repr(var_name))\n    else:\n        return val\n")),(0,a.kt)("p",null,"When the method visits a ",(0,a.kt)("em",{parentName:"p"},"Var")," node as in the above AST picture, it first gets the variable's name and then uses that name as a key into the ",(0,a.kt)("inlineCode",{parentName:"p"},"GLOBAL_SCOPE")," dictionary to get the variable's value. If it can find the value, it returns it, if not - it raises a ",(0,a.kt)("em",{parentName:"p"},"NameError"),' exception. Here are the contents of the symbol table before evaluating the assignment statement "b := a + 7;":'),(0,a.kt)("img",{src:"./imgs/lsbasi_part9_ast_st02.png",alt:""}),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Wrapping Up")),(0,a.kt)("p",null,'In this article we introduce a number of "hacks" which will be removed as we move forward with the series:'),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"The program grammar rule is incomplete. We'll extend it later with additional elements."),(0,a.kt)("li",{parentName:"ol"},"Pascal is a statically typed language, and you must declare a variable and its type before using it. But, as you saw, that was not the case in this article."),(0,a.kt)("li",{parentName:"ol"},"No type checking so far. It's not a big deal at this point, but I just wanted to mention it explicitly. Once we add more types to our interpreter we'll need to report an error when you try to add a string and an integer, for example."),(0,a.kt)("li",{parentName:"ol"},"A symbol table in this part is a simple Python dictionary that does double duty as a memory space. Worry not: symbol tables are such an important topic that I'll have several articles dedicated just to them. And memory space (runtime management) is a topic of its own."),(0,a.kt)("li",{parentName:"ol"},"In our simple calculator from previous articles, we used a forward slash character '/' for denoting integer division. In Pascal, though, you have to use a keyword div to specify integer division."),(0,a.kt)("li",{parentName:"ol"},"There is also one hack that I introduced on purpose in Pascal all reserved keywords and identifiers are case-insensitive, but the interpreter in this article treats them as case-sensitive.")),(0,a.kt)("img",{src:"./imgs/lsbasi_part9_hacks.png",alt:""}))}f.isMDXComponent=!0}}]);