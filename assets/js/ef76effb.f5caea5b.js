"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[4033],{3905:(e,n,a)=>{a.d(n,{Zo:()=>p,kt:()=>g});var t=a(67294);function o(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function r(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function l(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?r(Object(a),!0).forEach((function(n){o(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function s(e,n){if(null==e)return{};var a,t,o=function(e,n){if(null==e)return{};var a,t,o={},r=Object.keys(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||(o[a]=e[a]);return o}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var i=t.createContext({}),c=function(e){var n=t.useContext(i),a=n;return e&&(a="function"==typeof e?e(n):l(l({},n),e)),a},p=function(e){var n=c(e.components);return t.createElement(i.Provider,{value:n},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},m=t.forwardRef((function(e,n){var a=e.components,o=e.mdxType,r=e.originalType,i=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=c(a),m=o,g=d["".concat(i,".").concat(m)]||d[m]||u[m]||r;return a?t.createElement(g,l(l({ref:n},p),{},{components:a})):t.createElement(g,l({ref:n},p))}));function g(e,n){var a=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var r=a.length,l=new Array(r);l[0]=m;var s={};for(var i in n)hasOwnProperty.call(n,i)&&(s[i]=n[i]);s.originalType=e,s[d]="string"==typeof e?e:o,l[1]=s;for(var c=2;c<r;c++)l[c]=a[c];return t.createElement.apply(null,l)}return t.createElement.apply(null,a)}m.displayName="MDXCreateElement"},87181:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var t=a(87462),o=(a(67294),a(3905));const r={title:"Updates, Gradual Rollouts, AutoScaling",sidebar_position:8},l=void 0,s={unversionedId:"kubernetes/scaling",id:"kubernetes/scaling",title:"Updates, Gradual Rollouts, AutoScaling",description:"Deployments are the recommended way to deal with scaling and application updates going forward.",source:"@site/docs/kubernetes/scaling.md",sourceDirName:"kubernetes",slug:"/kubernetes/scaling",permalink:"/docs/kubernetes/scaling",draft:!1,tags:[],version:"current",sidebarPosition:8,frontMatter:{title:"Updates, Gradual Rollouts, AutoScaling",sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"Networking, Load Balancers, Ingress",permalink:"/docs/kubernetes/networking"},next:{title:"Deployments, Jobs, and DaemonSets",permalink:"/docs/kubernetes/workloads"}},i={},c=[{value:"Application autoscaling",id:"application-autoscaling",level:2},{value:"Scaling a cluster",id:"scaling-a-cluster",level:3}],p={toc:c};function d(e){let{components:n,...a}=e;return(0,o.kt)("wrapper",(0,t.Z)({},p,a,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Deployments are the recommended way to deal with scaling and application updates going forward."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pods -l name=<pod-name>\nkubectl scale --replicas=3 rc/<pod-name>\n")),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"rolling-update")," command allows us to update entire RCs or just the underlying Docker image used by each replica."),(0,o.kt)("p",null,"We can also specify an update interval, which will allow us to update one pod at a time and wait until proceeding to the next."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'kubectl rolling-update <pod-name> [<new-pod-name>] [OPTION] --update-period="2m"\n')),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("p",null,"A/B test configuration example")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# pod-AB-service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: node-js-scale-ab\n  labels:\n    service: node-js-scale-ab\nspec:\n  type: LoadBalancer\n  ports:\n    - port: 80\n  sessionAffinity: ClientIP # session affinity to service and node\n  selector:\n    service: node-js-scale-ab\n\n#  pod-A-controller.yaml\napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: node-js-scale-a\n  labels:\n    name: node-js-scale-a\n    version: '0.2'\n    service: node-js-scale-ab\nspec:\n  replicas: 2\n  selector:\n    name: node-js-scale-a\n    version: '0.2'\n    service: node-js-scale-ab\n  template:\n    metadata:\n      labels:\n        name: node-js-scale-a\n        version: '0.2'\n        service: node-js-scale-ab\n    spec:\n      containers:\n        - name: node-js-scale\n          image: pod-scaling:0.2\n          ports:\n            - containerPort: 80\n          livenessProbe:\n            httpGet:\n              path: /\n              port: 80\n            initialDelaySeconds: 30\n            timeoutSeconds: 5\n          readinessProbe:\n            httpGet:\n              path: /\n              port: 80\n            initialDelaySeconds: 30\n            timeoutSeconds: 1\n\n#  pod-A-controller.yaml\napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: node-js-scale-b\n  labels:\n    name: node-js-scale-b\n    version: '0.3'\n    service: node-js-scale-ab\nspec:\n  replicas: 2\n  selector:\n    name: node-js-scale-b\n    version: '0.3'\n    service: node-js-scale-ab\n  template:\n    metadata:\n      labels:\n        name: node-js-scale-b\n        version: '0.3'\n        service: node-js-scale-ab\n    spec:\n      containers:\n        - name: node-js-scale\n          image: pod-scaling:0.3\n          ports:\n            - containerPort: 80\n          livenessProbe:\n            httpGet:\n              path: /\n              port: 80\n            initialDelaySeconds: 30\n            timeoutSeconds: 5\n          readinessProbe:\n            httpGet:\n              path: /\n              port: 80\n            initialDelaySeconds: 30\n            timeoutSeconds: 1\n\n")),(0,o.kt)("p",null,"In a true A/B test, we would now want to start collecting metrics on the visit to each version. Again, we have ",(0,o.kt)("inlineCode",{parentName:"p"},"sessionAffinity")," set to ClientIP, so all requests will go to the same pod."),(0,o.kt)("p",null,"Since the versions are each on their own pod, one can easily separate logging and even add a logging container to the pod definition for a sidecar logging pattern."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"# finish the A/B test, transition to version 0.3\nkubectl scale --replicas=3 rc/node-js-scale-b\nkubectl scale --replicas=1 rc/node-js-scale-a\nkubectl scale --replicas=4 rc/node-js-scale-b\nkubectl scale --replicas=0 rc/node-js-scale-a\n\n# remove the controller\nkubectl delete rc/node-js-scale-a\n"))),(0,o.kt)("h2",{id:"application-autoscaling"},"Application autoscaling"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Kubernetes makes a distinction between ",(0,o.kt)("em",{parentName:"p"},"horizontal scaling"),", which involves creating additional replicas of a Pod, and ",(0,o.kt)("em",{parentName:"p"},"vertical scaling"),", which involves increasing the resources required for a particular Pod (e.g., increasing the CPU required for the Pod).")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Horizontal Pod Autoscaler"),": This resource type is really useful as it gives us a way to automatically set thresholds (CPU/QPS/Memory) for scaling our application."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# HPA configurations\napiVersion: v1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: node-js-scale-ab\nspec:\n  minReplicas: 1\n  maxReplicas: 3\n  scaleTargetRef:\n    apiVersion: v1\n    kind: ReplicationController\n    name: node-js-scale\n  targetCPUUtilizationPercentage: 20\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get hpa\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# generate some load to the service\napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: boomload\nspec:\n  replicas: 1\n  selector:\n    app: loadgenerator\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n    spec:\n      containers:\n        - name: boom\n          image: williamyeh/boom\n          command: ['/bin/sh', '-c']\n          args:\n            [\n              'while true; do boom http://node-js-scale/ -c 10 -n 100; sleep 1; done',\n            ]\n")),(0,o.kt)("h3",{id:"scaling-a-cluster"},"Scaling a cluster"),(0,o.kt)("p",null,"Additionally, we need some autoscaling capability in the clusters other than applications."),(0,o.kt)("p",null,"The following example shows how to set the environment variables for auto-scaling before running ",(0,o.kt)("inlineCode",{parentName:"p"},"kube-up.sh"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"export NUM_MINIONS=5\nexport KUBE_AUTOSCALER_MIN_NODES=2\nexport KUBE_AUTOSCALER_MAX_NODES=5\nexport KUBE_ENABLE_CLUSTER_AUTOSCALER=true\n")),(0,o.kt)("p",null,"Once you start a cluster with these settings, your cluster will automatically scale up and down with the minimum and maximum limits based on compute resource usage in the cluster."))}d.isMDXComponent=!0}}]);