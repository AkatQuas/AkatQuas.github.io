"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[3848],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>h});var r=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var s=r.createContext({}),p=function(e){var n=r.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},c=function(e){var n=p(e.components);return r.createElement(s.Provider,{value:n},e.children)},f="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},m=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),f=p(t),m=a,h=f["".concat(s,".").concat(m)]||f[m]||u[m]||o;return t?r.createElement(h,l(l({ref:n},c),{},{components:t})):r.createElement(h,l({ref:n},c))}));function h(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,l=new Array(o);l[0]=m;var i={};for(var s in n)hasOwnProperty.call(n,s)&&(i[s]=n[s]);i.originalType=e,i[f]="string"==typeof e?e:a,l[1]=i;for(var p=2;p<o;p++)l[p]=t[p];return r.createElement.apply(null,l)}return r.createElement.apply(null,t)}m.displayName="MDXCreateElement"},14680:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>l,default:()=>f,frontMatter:()=>o,metadata:()=>i,toc:()=>p});var r=t(87462),a=(t(67294),t(3905));const o={title:"05",tags:["lisp","interpreter"]},l=void 0,i={unversionedId:"lisp-interpreter-in-py/chapter-05",id:"lisp-interpreter-in-py/chapter-05",title:"05",description:"We're going to use all the knowledge you've gained from previous articles in the series and learn how to parse and interpret arithmetic expressions that have any number of addition, subtraction, multiplication, and division operators.",source:"@site/docs/lisp-interpreter-in-py/chapter-05.md",sourceDirName:"lisp-interpreter-in-py",slug:"/lisp-interpreter-in-py/chapter-05",permalink:"/docs/lisp-interpreter-in-py/chapter-05",draft:!1,tags:[{label:"lisp",permalink:"/docs/tags/lisp"},{label:"interpreter",permalink:"/docs/tags/interpreter"}],version:"current",frontMatter:{title:"05",tags:["lisp","interpreter"]},sidebar:"tutorialSidebar",previous:{title:"04",permalink:"/docs/lisp-interpreter-in-py/chapter-04"},next:{title:"06",permalink:"/docs/lisp-interpreter-in-py/chapter-06"}},s={},p=[],c={toc:p};function f(e){let{components:n,...o}=e;return(0,a.kt)("wrapper",(0,r.Z)({},c,o,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"We're going to use all the knowledge you've gained from previous articles in the series and learn how to parse and interpret arithmetic expressions that have any number of addition, subtraction, multiplication, and division operators."),(0,a.kt)("p",null,"Before diving in and writing some code, let's talk about the associativity and precedence of operators."),(0,a.kt)("img",{src:"./imgs/lsbasi_part5_precedence.png",alt:""}),(0,a.kt)("p",null,"Above is the precedence table, you can tell that operators + and - have the same precedence level and they are both left-associative. You can also see that operators ","*"," and / are also left-associative, have the same precedence among themselves but have higher-precedence than addition and subtraction operators."),(0,a.kt)("p",null,"Here are the rules for how to construct a grammar from the precedence table:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"For each level of precedence define a non-terminal. The body of a production for the non-terminal should contain arithmetic operators from that level and non-terminals for the next higher level of precedence.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Create an additional non-terminal ",(0,a.kt)("em",{parentName:"p"},"factor")," for the basic units of expression, in this case, integers. The general rule is that if you have N levels of precedence, you will need N+1 non-terminals in total: one non-terminal for each level plus one non-terminal for basic units of expression."))),(0,a.kt)("p",null,"According to Rule 1 we will define two non-terminals: a non-terminal called ",(0,a.kt)("em",{parentName:"p"},"expr")," for level 2 and a non-terminal called ",(0,a.kt)("em",{parentName:"p"},"term")," for level 1. And by following Rule 2 we will define a ",(0,a.kt)("em",{parentName:"p"},"factor")," non-terminal for basic units of arithmetic expressions, integers."),(0,a.kt)("p",null,"The ",(0,a.kt)("em",{parentName:"p"},"start symbol")," will be ",(0,a.kt)("em",{parentName:"p"},"expr")," and the ",(0,a.kt)("em",{parentName:"p"},"expr")," production will contain a body representing the use of operators from level 2, which in this case are operators + and -, and will contain ",(0,a.kt)("em",{parentName:"p"},"term")," non-terminals for the next higher level of precedence, level 1:"),(0,a.kt)("img",{src:"./imgs/lsbasi_part5_cfg_expr.png",alt:""}),(0,a.kt)("p",null,"The ",(0,a.kt)("em",{parentName:"p"},"term")," production will have a body representing the use of operators from level 1, which are operators ",(0,a.kt)("em",{parentName:"p"}," and /, and it will contain the non-terminal "),"factor","*"," for the basic units of expression, integers:"),(0,a.kt)("img",{src:"./imgs/lsbasi_part5_cfg_term.png",alt:""}),(0,a.kt)("p",null,"And the production for the non-terminal ",(0,a.kt)("em",{parentName:"p"},"factor")," will be:"),(0,a.kt)("img",{src:"./imgs/lsbasi_part5_cfg_factor.png",alt:""}),(0,a.kt)("p",null,'Here is a syntax diagram that corresponds to the grammar above, each rectangular box in the diagram is a "method call" to another diagram.'),(0,a.kt)("img",{src:"./imgs/lsbasi_part5_syntaxdiagram.png",alt:""}),(0,a.kt)("p",null,"To drive the precedence of operators point home, let's take a look at the decomposition of the same arithmetic expression ",(0,a.kt)("em",{parentName:"p"},"7 + 5 ")," 2",(0,a.kt)("em",{parentName:"p"}," done in accordance with our grammar and syntax diagrams above. This is just another way to show that "),"higher-precedence",(0,a.kt)("em",{parentName:"p"}," operators execute before operators with "),"lower-precedence","*",":"),(0,a.kt)("img",{src:"./imgs/lsbasi_part5_exprdecomp.png",alt:""}),(0,a.kt)("p",null,"The following are the main changes compared with the code from ",(0,a.kt)("a",{target:"_blank",href:t(47694).Z},"calc4.py")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"The ",(0,a.kt)("em",{parentName:"p"},"Lexer")," class can now tokenize +,-,","*"," and / (Nothing new here, we just combined code from previous articles into one class that supports all those tokens)")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Recall that each rule (production), R, defined in the grammar, becomes a method with the same name, and references to that rule become a method call: R(). As a result the ",(0,a.kt)("em",{parentName:"p"},"Interpreter")," class now has three methods that correspond to non-terminals in the grammar: ",(0,a.kt)("em",{parentName:"p"},"expr, term, factor"),"."))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# Token types\n#\n# EOF (end-of-file) token is used to indicate that\n# there is no more input left for lexical analysis\nINTEGER, PLUS, MINUS, MUL, DIV, EOF = (\n    'INTEGER', 'PLUS', 'MINUS', 'MUL', 'DIV', 'EOF'\n)\n\n\nclass Token(object):\n    def __init__(self, type, value):\n        # token type: INTEGER, PLUS, MINUS, MUL, DIV, or EOF\n        self.type = type\n        # token value: non-negative integer value, '+', '-', '*', '/', or None\n        self.value = value\n\n    def __str__(self):\n        \"\"\"String representation of the class instance.\n\n        Examples:\n            Token(INTEGER, 3)\n            Token(PLUS, '+')\n            Token(MUL, '*')\n        \"\"\"\n        return 'Token({type}, {value})'.format(\n            type=self.type,\n            value=repr(self.value)\n        )\n\n    def __repr__(self):\n        return self.__str__()\n\n\nclass Lexer(object):\n    def __init__(self, text):\n        # client string input, e.g. \"3 * 5\", \"12 / 3 * 4\", etc\n        self.text = text\n        # self.pos is an index into self.text\n        self.pos = 0\n        self.current_char = self.text[self.pos]\n\n    def error(self):\n        raise Exception('Invalid character')\n\n    def advance(self):\n        \"\"\" Adavance the `pos` pointer and set the `current_char` variable. \"\"\"\n        self.pos += 1\n        if self.pos > len(self.text) - 1:\n            self.current_char = None    # Indicates end of input\n        else:\n            self.current_char = self.text[self.pos]\n\n    def skip_whitespace(self):\n        while self.current_char is not None and self.current_char.isspace():\n            self.advance()\n\n    def integer(self):\n        \"\"\" Return a (multidigit) integer consumed from the input \"\"\"\n        result = ''\n        while self.current_char is not None and self.current_char.isdigit():\n            result += self.current_char\n            self.advance()\n        return int(result)\n\n    def get_next_token(self):\n        \"\"\"Lexical analyzer (also known as scanner or tokenizer)\n\n        This method is responsible for breaking a sentence\n        apart into tokens. One token at a time.\n        \"\"\"\n        while self.current_char is not None:\n            if self.current_char.isspace():\n                self.skip_whitespace()\n                continue\n\n            if self.current_char.isdigit():\n                return Token(INTEGER, self.integer())\n\n            if self.current_char == '+':\n                self.advance()\n                return Token(PLUS, '+')\n\n            if self.current_char == '-':\n                self.advance()\n                return Token(MINUS, '-')\n\n            if self.current_char == '*':\n                self.advance()\n                return Token(MUL, '*')\n\n            if self.current_char == '/':\n                self.advance()\n                return Token(DIV, '/')\n\n            self.error()\n        return Token(EOF, None)\n\nclass Interpreter(object):\n    def __init__(self, lexer):\n        self.lexer = lexer\n        # set current token to the first token taken from the input\n        self.current_token = self.lexer.get_next_token()\n\n    def error(self):\n        raise Exception('Invalid syntax')\n\n    def eat(self, token_type):\n        # compare the current token type with the passed token\n        # type and if they match then \"eat\" the current token\n        # and assign the next token to the self.current_token,\n        # otherwise raise an exception.\n        if self.current_token.type == token_type:\n            self.current_token = self.lexer.get_next_token()\n        else:\n            self.error()\n\n    def factor(self):\n        \"\"\"factor : INTEGER\"\"\"\n        token = self.current_token\n        self.eat(INTEGER)\n        return token.value\n\n    def term(self):\n        \"\"\" term: factor (( MUL | DIV ) factor)* \"\"\"\n        result = self.factor()\n\n        while self.current_token.type in (MUL, DIV):\n            token = self.current_token\n            if token.type == MUL:\n                self.eat(MUL)\n                result = result * self.factor()\n            elif token.type == DIV:\n                self.eat(DIV)\n                result = result / self.factor()\n\n        return result\n\n    def expr(self):\n        \"\"\" Arithmetic expressoin parser / interpreter.\n\n        calc>  14 + 2 * 3 - 6 / 2\n        17\n\n        expr   : term ((PLUS | MINUS) term)*\n        term   : factor ((MUL | DIV) factor)*\n        factor : INTEGER\n        \"\"\"\n        result = self.term()\n\n        while self.current_token.type in (PLUS, MINUS):\n            token = self.current_token\n            if token.type == PLUS:\n                self.eat(PLUS)\n                result += self.term()\n            elif token.type == MINUS:\n                self.eat(MINUS)\n                result -= self.term()\n\n        return result\n\ndef main():\n    while True:\n        try:\n            text = input('calc>')\n        except EOFError:\n            break\n        if not text:\n            continue\n        lexer = Lexer(text)\n        interpreter = Interpreter(lexer)\n        result = interpreter.expr()\n        print(result)\n\n\nif __name__ == '__main__':\n    main()\n")),(0,a.kt)("p",null,"Next we'll add the parentheses."))}f.isMDXComponent=!0},47694:(e,n,t)=>{t.d(n,{Z:()=>r});const r=t.p+"assets/files/calc4-f5e3a6a913e419c175c0ce309619ceba.py"}}]);